"""
Core-Inference: Ollama API management, caching, and dynamic context expansion.

Public API for LLM inference operations.
"""

from wellactually.cores.inference.facade import InferenceFacade

__all__ = ["InferenceFacade"]
